{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from data_utils import (\n",
    "    is_valid_python,\n",
    "    insert_instruction_as_docstring,\n",
    "    break_into_definition_and_solution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Alpaca 20k\n",
    "\n",
    "https://huggingface.co/datasets/sahil2801/CodeAlpaca-20k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'input', 'instruction'],\n",
       "        num_rows: 20022\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_alpaca_dataset = load_dataset(\"sahil2801/CodeAlpaca-20k\")\n",
    "code_alpaca_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valid Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bbbe8ab00c342ba94563ccfd46b5fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/8975 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:9: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "<string>:9: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n"
     ]
    }
   ],
   "source": [
    "# Filter the dataset to only include `output` that is valid python code\n",
    "# We might find some code snippets that are not valid python code like:\n",
    "# 'Height of triangle = opposite side length * sin (angle) / side length'\n",
    "code_alpaca_dataset = code_alpaca_dataset.filter(lambda x: is_valid_python(x['output']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cf44d1a97649d5af954852f44946fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finally get only the examples that start with 'def', as at HumanEval we are only interested in functions\n",
    "# and we need to learn to use the function signature with the parameters to generate the function body\n",
    "code_alpaca_dataset = code_alpaca_dataset.filter(lambda x: x['output'].startswith('def'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'input', 'instruction'],\n",
       "        num_rows: 3897\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_alpaca_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transform Code Alpaca's data into the format tha HumanEval uses. To do so we prepare some utility functions at `data_utils.py`. We can summarize the steps as going from:\n",
    "\n",
    "1. Code Alpaca's data format:\n",
    "```python\n",
    "output = '''\n",
    "def foo():\n",
    "    return 1\n",
    "'''\n",
    "instructions = \"Write a function that returns 1\"\n",
    "```\n",
    "\n",
    "2. To HumanEval's data format:\n",
    "```python\n",
    "instructions = '''\n",
    "def foo():\n",
    "    \"\"\" Write a function that returns 1\n",
    "    \"\"\"\n",
    "'''\n",
    "output = '''\n",
    "    return 1\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## Inputs:\n",
      "def find_num_distinct_states(matrix):\n",
      "    \"\"\" Write a function to find the number of distinct states in a given matrix.\n",
      "    \"\"\"\n",
      "\n",
      "## Outputs:\n",
      "    states = set()\n",
      "    for row in matrix:\n",
      "        state = \"\".join([str(x) for x in row])\n",
      "        states.add(state)\n",
      "    return len(states)\n"
     ]
    }
   ],
   "source": [
    "case = 1\n",
    "instruction = code_alpaca_dataset['train'][case][\"instruction\"]\n",
    "code_def = code_alpaca_dataset['train'][case][\"output\"]\n",
    "full = insert_instruction_as_docstring(instruction, code_def)\n",
    "inputs, outputs = break_into_definition_and_solution(full)\n",
    "print(f\"\\n## Inputs:\\n{inputs}\")\n",
    "print(f\"\\n## Outputs:\\n{outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprare_prompt_completion(example):\n",
    "    instruction = example[\"instruction\"]\n",
    "    code_def = example[\"output\"]\n",
    "    full = insert_instruction_as_docstring(instruction, code_def)\n",
    "    inputs, outputs = break_into_definition_and_solution(full)\n",
    "    example[\"prompt\"] = inputs\n",
    "    example[\"completion\"] = outputs\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1d11044d007441d8f72a218df6ab901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "updated_dataset = code_alpaca_dataset.map(update_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now process the dataset to insert the inputs and outputs\n",
    "# Iterate over the dataset and insert the inputs and outputs\n",
    "for split in code_alpaca_dataset.keys():\n",
    "    for i, example in enumerate(code_alpaca_dataset[split]):\n",
    "        instruction = example[\"instruction\"]\n",
    "        code_def = example[\"output\"]\n",
    "        full = insert_instruction_as_docstring(instruction, code_def)\n",
    "        inputs, outputs = break_into_definition_and_solution(full)\n",
    "        code_alpaca_dataset[split][i][\"prompt\"] = inputs\n",
    "        code_alpaca_dataset[split][i][\"completion\"] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'def countVowels(str): \\n\\tvowel = 0\\n\\tfor i in str: \\n\\t\\tif i.lower() in [\\'a\\', \\'e\\', \\'i\\', \\'o\\', \\'u\\']: \\n\\t\\t\\tvowel += 1\\n\\treturn vowel \\n\\n# Driver code \\nstr = \"Hello World\"\\nprint(\"Number of vowels are:\", countVowels(str))',\n",
       " 'input': 'Hello World',\n",
       " 'instruction': 'Create a Python program to accept a string from the user and print out the number of vowels in the string.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'input', 'instruction'],\n",
       "        num_rows: 3897\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_alpaca_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Definition:\n",
      "def find_num_distinct_states(matrix):\n",
      "    \"\"\" Write a function to find the number of\n",
      "    distinct states in a given matrix.\n",
      "    \"\"\"\n",
      "\n",
      "## Solution:\n",
      "    states = set()\n",
      "    for row in matrix:\n",
      "        state = \"\".join([str(x) for x in row])\n",
      "        states.add(state)\n",
      "    return len(states)\n"
     ]
    }
   ],
   "source": [
    "print(f\"## Definition:\\n{d}\")\n",
    "print(f\"\\n## Solution:\\n{s}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
